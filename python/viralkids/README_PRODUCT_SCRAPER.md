# ğŸ•·ï¸ Product Scraper API - ViralKids

API Python para webscraping de produtos afiliados usando estrutura Agno.

## ğŸš€ InstalaÃ§Ã£o

```bash
cd python/viralkids
pip install -r requirements.txt
```

## ğŸ“‹ DependÃªncias

- `fastapi` - Framework web
- `aiohttp` - Cliente HTTP assÃ­ncrono
- `beautifulsoup4` - Parser HTML
- `agno` - Framework de agentes AI
- `groq` - Modelo de linguagem (via Agno)

## ğŸ”§ ConfiguraÃ§Ã£o

Crie um arquivo `.env`:

```env
SCRAPER_PORT=8002
AGNO_MODEL_ID=groq/llama-3.1-8b-instant
GROQ_API_KEY=sua-chave-groq-aqui
```

## ğŸƒ Executar

```bash
python api_product_scraper.py
```

Ou usando uvicorn:

```bash
uvicorn api_product_scraper:app --host 0.0.0.0 --port 8002
```

## ğŸ“¡ Endpoints

### POST `/scrape`

Faz scraping sÃ­ncrono de um produto.

**Request:**
```json
{
  "url": "https://www.shopee.com.br/produto...",
  "platform": "shopee",
  "category_id": "cat-123",
  "user_id": "user-456",
  "unit_id": "unit-789"
}
```

**Response:**
```json
{
  "success": true,
  "platform": "shopee",
  "url": "https://www.shopee.com.br/produto...",
  "scraped_at": "2024-01-15T10:30:00",
  "data": {
    "name": "Nome do Produto",
    "price": 99.90,
    "originalPrice": 149.90,
    "images": ["url1", "url2"],
    "description": "DescriÃ§Ã£o do produto",
    "rating": 4.5,
    "specifications": {},
    "tags": ["tag1", "tag2"],
    "features": ["feature1"]
  }
}
```

### POST `/scrape/async`

Faz scraping assÃ­ncrono (em background).

## ğŸ¯ Plataformas Suportadas

- âœ… Shopee
- âœ… Amazon
- âœ… Magalu
- âœ… Mercado Livre
- âœ… Americanas
- âœ… Casas Bahia
- âœ… Outros (scraping genÃ©rico)

## ğŸ”„ Fluxo de Processamento

1. Frontend cadastra produto afiliado â†’ Node.js API
2. Node.js cria registro com status `pending`
3. Node.js chama Python Scraper API
4. Python faz webscraping e retorna dados
5. Node.js cria produto completo na collection
6. Status atualizado para `completed`

## ğŸ› Tratamento de Erros

- Retry automÃ¡tico (atÃ© 3 tentativas)
- Logs detalhados de erros
- Status tracking (`pending`, `processing`, `completed`, `failed`, `retrying`)

## ğŸ“ Notas

- O scraper usa BeautifulSoup para parsing HTML
- Agno Ã© usado para enriquecer e estruturar dados extraÃ­dos
- Suporta detecÃ§Ã£o automÃ¡tica de plataforma
- Timeout de 30 segundos por requisiÃ§Ã£o

